{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from itertools import chain\n",
    "import os\n",
    "from xml.etree import ElementTree as ET\n",
    "from tempfile import NamedTemporaryFile\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict, Counter, namedtuple\n",
    "import fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Źródło danych \n",
    "[Polski Korpus Sejmowy](http://clip.ipipan.waw.pl/PSC) - Sittings, kadencja 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"PSC/Posiedzenia/kadencja8\"\n",
    "dirs = os.listdir(root)\n",
    "ns = {'namespace': 'http://www.tei-c.org/ns/1.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fullname(header_elem):\n",
    "    _id = \"#\" + header_elem.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "    function_name = header_elem.find('./namespace:persName', ns).text\n",
    "    name = \" \".join(function_name.split()[-2:])\n",
    "    return name, _id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_texts():\n",
    "    texts = map(lambda d: ET.parse(f\"{root}/{d}/text_structure.xml\").getroot(),\n",
    "                dirs)\n",
    "    texts_elems = chain.from_iterable(\n",
    "        map(lambda e: e.findall('.//namespace:u', ns), texts))\n",
    "    sentences = map(lambda e: (e.get('who'), e.text), texts_elems)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def parse_headers():\n",
    "    headers = map(lambda d: ET.parse(f\"{root}/{d}/header.xml\").getroot(), dirs)\n",
    "    person_elems = chain.from_iterable(\n",
    "        map(lambda x: x.findall(\".//namespace:person\", ns), headers))\n",
    "    persons = map(fullname, person_elems)\n",
    "    name_id = dict(set(persons))\n",
    "    return name_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_partia_dict(name_id):\n",
    "    name_partia = dict()\n",
    "    with open('poslowie.csv') as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter=';')\n",
    "        for x in reader:\n",
    "            if x[0] in name_id:\n",
    "                _id = name_id[x[0]]\n",
    "                name_partia[_id] = x[1]\n",
    "    return name_partia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeled_sentences():\n",
    "    name_id_dict = parse_headers()\n",
    "    name_partia = name_partia_dict(name_id_dict)\n",
    "    for sentence in parse_texts():\n",
    "        name_id = sentence[0]\n",
    "        if name_id in name_partia:\n",
    "            partia = name_partia[sentence[0]] \n",
    "            text = sentence[1]\n",
    "            labeled_text = f\"__label__{partia} {text}\"\n",
    "            yield  labeled_text, partia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_true, predictions, average):\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "        y_true, predictions, average=average)\n",
    "    print()\n",
    "    print(average)\n",
    "    print('Precision', precision)\n",
    "    print('Recall', recall)\n",
    "    print('F1', fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_file(x_train):\n",
    "    train_file = NamedTemporaryFile(mode='w')\n",
    "    for x in x_train:\n",
    "        train_file.write(x + \"\\n\")\n",
    "    return train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,x_test):\n",
    "    predictions = list(map(lambda s: model.predict(s)[0][0], x_test))\n",
    "    y_true = [sentence.split()[0] for sentence in x_test]\n",
    "    print_results(y_true, predictions, average='micro')\n",
    "    print_results(y_true, predictions, average='macro')\n",
    "    print(classification_report(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = zip(*labeled_sentences())\n",
    "x_data = np.array(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "micro\n",
      "Precision 0.5708110287365332\n",
      "Recall 0.5708110287365332\n",
      "F1 0.5708110287365332\n",
      "\n",
      "macro\n",
      "Precision 0.5202335429680457\n",
      "Recall 0.4142591483921965\n",
      "F1 0.4482066781834884\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "   __label__Kukiz15       0.50      0.35      0.41      3459\n",
      "__label__Nowoczesna       0.46      0.36      0.40      4802\n",
      "       __label__PIS       0.63      0.67      0.65     14627\n",
      "        __label__PO       0.56      0.70      0.62     15729\n",
      "       __label__PSL       0.49      0.32      0.39      3345\n",
      "       __label__WIS       0.66      0.38      0.49      1545\n",
      "     __label__other       0.34      0.12      0.18      1140\n",
      "\n",
      "        avg / total       0.56      0.57      0.56     44647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.25)\n",
    "\n",
    "for train_index, test_index in stratified_split.split(data_x, data_y):\n",
    "    x_train, x_test = x_data[train_index], x_data[test_index]\n",
    "    train_file = prepare_train_file(x_train)\n",
    "    model = fastText.train_supervised(\n",
    "        input=train_file.name,\n",
    "        epoch=25,\n",
    "        lr=1.0,\n",
    "        wordNgrams=2,\n",
    "        verbose=2,\n",
    "        minCount=1)\n",
    "    evaluate(model,x_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
