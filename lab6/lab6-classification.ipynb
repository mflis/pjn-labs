{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from  itertools import tee, chain, islice, groupby\n",
    "from math import log\n",
    "from operator import itemgetter,attrgetter\n",
    "from itertools import takewhile\n",
    "import requests\n",
    "import re\n",
    "from collections import namedtuple "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "- 2018 has 990 judgements. 786 has justification. That means 20% of judgements has no justification. Quite weird. It turns out that half of these judgements contains word `oddalać (remove)` in some form. What about rest of judgements? Why they do not contain justification?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/marcin/Desktop/SemestrVIII/PJN'\n",
    "year = \"2018\"\n",
    "json_data_dir = f\"{root_dir}/data/json\"\n",
    "\n",
    "patterns = {\n",
    "    re.compile('A?C.*') : 'civil',\n",
    "    re.compile('A?U.*') : 'insurance',\n",
    "    re.compile('A?K.*') : 'criminal', \n",
    "    re.compile('G.*') :  'economic',\n",
    "    re.compile('A?P.*'): 'work', \n",
    "    re.compile('R.*'): 'family', \n",
    "    re.compile('W.*') : 'violations', \n",
    "    re.compile('Am.*'): 'competition'  ,\n",
    "    re.compile('.*'): 'other' \n",
    "    \n",
    "    }\n",
    "\n",
    "common_words = ['w', 'z', 'na', 'i', 'do',\n",
    " 'nie', 'o', 'k', 'r', 'że',\n",
    " 'art', 'dnia', 'się', 'od', 'a',\n",
    " 'przez', 'sąd', 'roku', 'pracy', 'za']\n",
    "\n",
    "common_tagged_words =['w:prep', 'z:prep', 'na:prep', \n",
    "                      'i:conj', 'do:prep', 'nie:qub', 'dzień:subst',\n",
    "                     'on:ppron3', 'o:prep', 'rok:brev', 'sąd:subst',\n",
    "                     'że:comp', 'koło:brev', 'praca:subst', 'ten:adj',\n",
    "                     'artykuł:brev', 'się:qub', 'od:prep', 'rok:subst', 'przez:prep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_number(filename):\n",
    "    return int(filename.split('-')[1].split('.')[0])\n",
    "\n",
    "def is_2017_in_file(filename):\n",
    "    return 2716 <= extract_file_number(filename) <= 3163 \n",
    "\n",
    "def is_2018_in_file(filename):\n",
    "    return 3163 <= extract_file_number(filename) <=  3173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category = namedtuple('Category',['label','caseNumber'])\n",
    "Text = namedtuple('Text',['id','words'])\n",
    "WithCategory = namedtuple('WithCategory', ['judgement','category'])\n",
    "Line = namedtuple('Line', ['id','words','category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(line):\n",
    "    justification = line.split('<h2>UZASADNIENIE</h2>')[1]\n",
    "    notags = re.sub(r\"<[^>]*>\", \" \", justification)\n",
    "    nobreaks = re.sub(r\"-\\n\", \" \", notags)\n",
    "    nodigits = re.sub(r\"\\d+\", \" \", nobreaks)\n",
    "    noromans = re.sub(r\"\\b[XVILMC]+\\b\", \"\", nodigits)\n",
    "    lower = noromans.lower()\n",
    "    words = filter(lambda x: x not in common_words, re.findall(r\"\\w+\", lower))\n",
    "    return words\n",
    "\n",
    "\n",
    "def filter_judgements(judgement):\n",
    "    return year in judgement['judgmentDate']  and \\\n",
    "    judgement['courtType'] in ['COMMON', 'SUPREME'] and \\\n",
    "    '<h2>UZASADNIENIE</h2>' in judgement['textContent']\n",
    "\n",
    "\n",
    "def map_category(judgement):\n",
    "    caseNumber = judgement['courtCases'][0]['caseNumber'].split(' ')\n",
    "    _, label = next(\n",
    "        filter(lambda pat: pat[0].match(caseNumber[1]), patterns.items()))\n",
    "    return Category(label, caseNumber)\n",
    "\n",
    "\n",
    "def judgements_raw(filename):\n",
    "    with open(os.path.join(json_data_dir, filename), 'r') as jsonFile:\n",
    "        judgements = json.load(jsonFile)['items']\n",
    "    return judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tagged(line):\n",
    "    _id, text = line\n",
    "    words = filter(lambda word: word not in common_tagged_words,\n",
    "                   text.split(' '))\n",
    "    return Text(_id, words)\n",
    "\n",
    "\n",
    "def tagged(categories_by_id):\n",
    "    lines = map(lambda l: Text._make(l.split(';')),\n",
    "                open('tagging-2018.data', 'r'))\n",
    "    int_id = map(lambda l: (int(l[0]),l[1]),lines)\n",
    "    filtered = filter(lambda l: l[0] in categories_by_id, int_id)\n",
    "    cleaned = map(clean_tagged, filtered)\n",
    "    return map(\n",
    "        lambda text: Line(text.id, text.words, categories_by_id[text.id]),\n",
    "        cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "judgements_files = filter(is_2018_in_file, os.listdir(json_data_dir))\n",
    "texts = chain.from_iterable(map(judgements_raw, judgements_files))\n",
    "filtered = filter(filter_judgements, texts)\n",
    "with_categories = map(lambda j: WithCategory(j, map_category(j).label), filtered)\n",
    "cleaned = map(\n",
    "    lambda j: Line(j.judgement['id'], clean_text(j.judgement['textContent']), j.category),\n",
    "    with_categories)\n",
    "cleaned_1, cleaned_2 = tee(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "judgements_files = filter(is_2018_in_file, os.listdir(json_data_dir))\n",
    "texts = chain.from_iterable(map(judgements_raw, judgements_files))\n",
    "filtered = filter(filter_judgements, texts)\n",
    "with_categories = map(lambda j: WithCategory(j, map_category(j).label), filtered)\n",
    "cleaned = map(\n",
    "    lambda j: Line(j.judgement['id'], clean_text(j.judgement['textContent']), j.category),\n",
    "    with_categories)\n",
    "cleaned_1, cleaned_2 = tee(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_id = dict(map(lambda line: (line.id, line.category), cleaned_2))\n",
    "tagged_categories = tagged(cat_id)\n",
    "tagged_sorted = sorted(tagged_categories,key= attrgetter('category'))\n",
    "tagged_groups = groupby(tagged_sorted,attrgetter('category'))\n",
    "tagged_grouped = dict((k, list(g)) for k, g in tagged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_categories = sorted(cleaned_1, key=itemgetter(2))\n",
    "groups = groupby(sorted_categories, itemgetter(2))\n",
    "grouped = dict((k, list(g)) for k, g in groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wnieść:praet'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tagged_grouped['civil'][0].words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
